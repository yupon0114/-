1
今から空中超音波ハプティックスにおける強化学習を用いた位相制御とToFによる対象物特定についての発表を行います。
2
研究背景についてです。​
ハプティクスとは、触感に関する技術領域です。​
中でも本研究である空中超音波ハプティクスは、​
音響放射圧を皮膚に加えることで非接触で触感を再現することができます。​
​続いて研究目標についてです。​
焦点の位相制御はまだ十分に確立されておらず、​
既存のシステムでは焦点を自動で動かすことは可能であるものの、処理速度に大きな課題があります。​
そこで、本研究では、ArduinoによるAD9833の制御をラズベリーパイによる制御に置き換え処理速度の高速化を目標としました。​
3
また、強化学習には代表的なアルゴリズムであるDQNおよびPPOを実装しました。​
それに加え、対象物体からの反射波をもとに三次元位置を特定することを目標としました。
4
強化学習について簡単に説明します。​
強化学習とはエージェントが行動を起こし、その結果として報酬を獲得し、これを通じてより高い価値の行動をする学習です。​
今回、行動を音源間の位相差として、状態をアクチュエータの音圧として考えていきます。​
報酬はマイク電圧と目標電圧の比に設定します。​
これを踏まえて、DQNとは、ある状態でどの行動を取ったら将来の報酬が大きくなるかを考えるアルゴリズムです。​
そのため、個々のチャンネルしか学習できません。​
PPOとは、報酬を多くするための方策を直接学習します。そのため、更新幅を制御して安定した学習を実現可能です。​
状態ではなく傾向を学習するため、複数chの同時​
学習が可能です。
5
次にDQNについて説明します。​
DQNはQ学習に深層学習を組み合わせたアルゴリズムです。​
先ほどと同様のルートをたどった場合、次の状態で取りうる最も高いQ値を、前回の行動のQ値として更新します。（アニメーション）​
学習率や割引率を単純化して考えた場合、0.7が1.0に更新されます。​
6
続いてPPOについて説明します。​
PPOは目的関数Lを最大化するパラメータを求める手法です。​
PPOでは、方針更新における変化の度合い r(Θ)の確率比が重要であり、「新しい方針」と「更新する前の直前の方針」の比を取ったものです。​
このr(Θ)の変化に応じて報酬を調整しています。​
更新が大きくなりすぎると学習が不安定になるため、最大化する目的関数Ｌにはクリップがついています。​
κ（カッパ）はハイパーパラメータであり、許容される更新の幅です。Aｔは期待アドバンテージであり平均より良い行動か悪い行動かを測る指標です。​
クリッピングによって方策更新の量を抑えることで、挑戦的なタスクに対処しても効果的なアルゴリズムです。
7
強化学習を効率的に行うために、学習範囲を狭める方向性局所化を行いました。​
赤い点は、音圧を実際に測定する位相角を示しており、90°おきの位置で音圧を確認することで、
隣接する位相の音圧の和が最大となる範囲を特定します。
その範囲の中で音圧がより大きい側の45°ずれた方を探索することで、​
音源の方向を段階的に絞り込んでいきます。​
8
​次にToFについて説明します。​
ToFとはTime of Flightのことで距離を測る方法のことです。今回は音波が返ってくるまでの時間で距離測定を行います。​
音波が対象物表面で反射して受音するまでの時間を「T」とし、光の速さ「C」と掛けることで、アクチュエータと対象物の往復距離（2Y）を求めることができます。
9
強化学習の実験装置構成図はこのようになっています。
処理速度の効率化をするためにArduinoをRaspiに置き換えました。​
また、マイクからのフィードバック電圧をRaspiPicoで計測しています。​
変更前の実験装置構成図は、制御系統はMini PC で強化学習を行い、位相情報を制御コントローラであるArudinoへ伝達します。​
この位相の情報を波形生成ICへ書き込み、出力された信号が増幅回路を通して最大60 Vppの電圧となってスピーカに印加され、超音波を放射します。​
アクチュエータとマイクロホンは正対しており、アクチュエータの円の中心を原点として、(x, y, z)の3次元座標中の任意の点にマイクロホンを設置します。
10
ToFの実験装置構成図はこのようになっています。​
強化学習でマイクを設置していた部分を対象物体に置き換えています。​
対象物に送信した信号の反射波をCapture boardで受け取り、時間データをMiniPCでグリッドサーチを行います。​
11
アクチュエータはこのように設計しました。
​12
実機での学習時間はArduinoをRaspiに置き換えたことで4分の1以下に短縮することが出来ました。​
また、DQNを使用するよりPPOを使用する方が学習時間が短縮されました。
13
実機での結果では、DQNよりPPOのほうが音圧が高い結果となりました。
また、いずれもDL有りのほうが最大音圧が高い結果となりました。​
これは、方向性局所化により探索範囲を制限することで、より効率的に焦点を探索できるからと考えられます。

これは、アクチュエータの中心から離れた座標である、x,y,z座標が10,10,50の音圧分布です。​
DQNのDL(方向性局所化)ありではx、y座標が10,10の位置の音圧が最も大きくなっていることが確認できますが、DLなしでは焦点が形成されませんでした。​
また、半値幅はDLありのものが12mmであると確認できます​

これは、アクチュエータの中心から離れた座標である、x,y,z座標が10,10,50の音圧分布です。​
DQNのDL(方向性局所化)ありではx、y座標が10,10の位置の音圧が最も大きくなっていることが確認できますが、DLなしでは焦点が形成されませんでした。​
また、半値幅はDLありのものが12mmであると確認できます​

これはDQNのアクチュエータの中心であるx,y,z座標が0,0,30の音圧分布です。​
DQNのDL(方向性局所化)ありではx、y座標が0,0の位置の音圧が最も大きくなっていることが確認できますが、DLなしでは焦点が分離し、正しい位置に形成されませんでした。​
また、半値幅と呼ばれる「触感が得られる指標」はDLありのものが縦9.5mm、横11mmであると確認できます。

続いてPPOのx,y,z座標が0,0,30の音圧分布です。​
どちらもx、y座標が0,0の位置の音圧が最も大きくなっていることが確認できます​
また、半値幅はそれぞれDLありが10mm、DLなしが8ｍｍでDLありのほうが半値幅が広いことが確認できます



余談の準備をしておいて下さい！
この怒り心頭のユーザー「RT4K7x8t」は他にもコメントを残しており、それも凄みがある。

というかモロ5部のキャラクター達を連想させる言い回しであり、そのコメントは各地で笑いを呼んだ。

なお、ワザップ恒例「出来ました！」の嘘報告に「どうせ改造」と煽っていたため、相当お怒りの様子。

お前は自分で自分を騙している。もしかしたら、自作自演なのか！？テメーのやっていることは！
（参考：ブチャラティ）

今すぐこのガセネタを削除しやがれ・・
（参考：アバッキオ ※ナランチャとする説も）

お前はこのウラ技実際にやってみたのかよ？
（参考：ミスタ）

貴方は全国のポケモンファンの持っているポケモンのゲームソフトのセーブデータを破壊しようとしている破壊神です。破壊の神です。そんなことをしているテメーが破壊されろ！
（参考：フーゴ）

お前はこのウラ技を何で知った？
（参考：リゾット）

ちなみに上記記述のユーザーが投稿したものでは無いがこの2つの別ユーザーのコメントを足して情弱パッショーネと呼ばれる事がある




16
続いて対象物の位置の特定について話します。​
位置特定実装は以上の5段階で行いました。
17
SP1が超音波を放射し、他のスピーカーが信号を受信する構成が検討されました。
しかし、SP1に隣接するSP2とSP8において、SP1からの著しい音響干渉が観測されました。
そのため、これらの2つのスピーカーは本研究から除外されました。
さらに、他のスピーカーから受信した波形の初期部分にも、SP1由来の干渉成分が含まれており、正確な受信時間の決定精度に影響を与えることが確認されました。​
この問題を解決するため、初期部分を除いた波形後半における20回の平均値を取りました。​
SP1から音響波を発射した場合、各スピーカーの時間差測定結果は図に示されています。​
図に示すように、すべてのスピーカーの測定時間はそれぞれSP1からの距離に比例しており、システム全体で一貫した動作が確認されています。v
18
グリッドサーチについて説明します。​
空中超音波ハプティクスの有効範囲を3次元で定義し、その範囲内で位置推定を行いまいました。​
指先の二点識別閾値が約2mmであることから、有効領域を1mm間隔のグリッドに分割し、測定距離と各グリッド点までのユークリッド距離を比較し、距離差が最小の点を推定位置と判定しています。​
また、右の図で示すように超音波スピーカの指向特性の60度の範囲に絞りました。​













